# Site to RSS Scraper

Une application FastAPI qui convertit n'importe quel site web en flux RSS en extrayant automatiquement les articles et leurs informations associÃ©es.

## ğŸš€ FonctionnalitÃ©s

- Conversion de n'importe quel site web en flux RSS
- Extraction automatique des articles avec :
  - Titre
  - Description
  - Image principale
  - Date de publication
  - Lien vers l'article
- DÃ©tection automatique du logo/favicon du site
- DÃ©duplication des articles
- Support du HTML dans les descriptions RSS

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- pip (gestionnaire de paquets Python)

## ğŸ› ï¸ Installation

1. Clonez le dÃ©pÃ´t :
```bash
git clone https://github.com/Achaire-Zogo/Kairos-Scrapping.git
cd Kairos-Scrapping
```

2. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt 
```
Ou 
```bash
pip3 install -r requirements.txt
```

## ğŸš€ DÃ©marrage

1. Lancez l'application :
```bash
python main.py
```
OU
```bash
python3 main.py
```

2. L'application sera accessible Ã  l'adresse : `http://localhost:5001`

## ğŸ“– Utilisation

1. Vous pouvez tester ici : `http://localhost:5001/docs`

### Endpoint principal

- URL : `/feed`
- MÃ©thode : GET
- ParamÃ¨tre : `url` (l'URL du site Ã  scraper)
- Exemple : `http://localhost:5000/feed?url=https://example.com`

### Format de retour

L'application retourne un flux RSS au format XML avec la structure suivante :

```xml
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
  <channel>
    <title>[Titre du site]</title>
    <link>[URL du site]</link>
    <description>[Description du site]</description>
    <image>
      <url>[URL du favicon/logo]</url>
      <title>[Titre du site]</title>
      <link>[URL du site]</link>
    </image>
    <item>
      <title>[Titre de l'article]</title>
      <link>[URL de l'article]</link>
      <description>
        <![CDATA[
          <img src="[URL de l'image]" />
          [Description de l'article]
        ]]>
      </description>
      <pubDate>[Date de publication]</pubDate>
    </item>
    <!-- Plus d'articles... -->
  </channel>
</rss>
```

### Codes de retour

- **200** : SuccÃ¨s
  - Retourne le flux RSS au format XML
- **400** : Erreur de requÃªte
  - URL invalide
  - Site inaccessible
  - Erreur lors du scraping
- **404** : Aucun article trouvÃ©
  - Le site est accessible mais aucun article n'a Ã©tÃ© dÃ©tectÃ©
- **500** : Erreur serveur
  - Erreur interne lors du traitement

## ğŸ” DÃ©tection des articles

L'application utilise plusieurs stratÃ©gies pour dÃ©tecter les articles :

1. **Structure HTML** : Recherche des balises `<article>`, `<div>`, `<section>`
2. **Titres** : DÃ©tection des `<h1>`, `<h2>`, `<h3>` comme titres d'articles
3. **Images** : Recherche des images principales via :
   - MÃ©tadonnÃ©es OpenGraph
   - Classes CSS spÃ©cifiques (featured, main, hero, etc.)
   - PremiÃ¨re image de taille significative
   - Images d'arriÃ¨re-plan en CSS

## ğŸ”„ DÃ©duplication

Les articles sont dÃ©dupliquÃ©s selon :
- Titres identiques (insensible Ã  la casse)
- URLs identiques

## ğŸ“ Limitations

- Les sites nÃ©cessitant une authentification ne sont pas supportÃ©s
- Le JavaScript dynamique n'est pas exÃ©cutÃ© lors du scraping
- Certains sites peuvent bloquer le scraping
- Le nombre d'articles est limitÃ© Ã  ceux prÃ©sents sur la page principale

## ğŸ“œ Licence

MIT License
